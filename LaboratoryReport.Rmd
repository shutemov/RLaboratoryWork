---
title: "Практическая работа Анализ данных в среде RStudio"
author: "Шутемов А.А., 6371"
date: "13 11 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Задание №1. Загружаем датасет.
Данный датасет использовался в предыдущей практической работе и содержит данные о медицинских отгулах работников на предприятии.

```{r}
path = "C:\\Users\\HP\\Documents\\GitHub\\RLaboratoryWork\\Absenteeism_at_work.csv"

dt <- read.table(path, header = T, sep=";")
```
### Размерность датасета
```{r}
dim(dt)
```
```{r}
names(dt)
```

### Отобразим таблицу частот классов
```{r}
tbl <- table(dt$Reason.for.absence)
tbl
```

## Задание №2. Выполним статистический анализ по показателям.

Приведем 5 статистик по показателям:

1. Причина отсутствия
2. Месяц в котором было зафиксировано отсутвие
3. Сезон
4. Индекс массы тела работника
5. Время отсутвия в часах


```{r}
summary(dt[,c("Reason.for.absence","Month.of.absence","Seasons","Body.mass.index","Absenteeism.time.in.hours")])
```
Отрисуем графики зависимостей:

1. Предположим, что причина отсутвия по медицинским причинам связана с индексом массы тела работника: 

```{r, echo=FALSE}
plot(dt$Reason.for.absence, dt$Body.mass.index)
```

Но, как видно, объекты распределены довольно равномерно.

2. Возьмем другую пару, индекс массы тела и рост работника:

```{r, echo=FALSE}
plot(dt$Body.mass.index, dt$Height)
```

Здесь уже виднеется некоторая корреляция данных.

3. Также построим график зависимости причины отсутствия и месяца:

```{r, echo=FALSE}
plot(dt$Reason.for.absence, dt$Month.of.absence)
```

Распределение объектов, так же как и в первом пункте, выглядит равномемерным.

## Задание №3. Выполним статистический анализ зависимости класса от отдельных показателей.

Для этого исследуем зависимость причин отгула работника от его социального статуса "курильщик":

1. Т.к. эти показатели являются качественными, построим таблицу сопряженности


```{r}
table <- table(dt$Reason.for.absence, dt$Social.smoker)

table

fisher.test(table,simulate.p.value=TRUE,B=1e3)
```
Отрисуем barplot этой зависимости:

```{r}
# Class ~ f1
tableClassOfF1 = table(dt$Social.smoker,dt$Reason.for.absence)
barplot(tableClassOfF1, legend.text = c("Не курильщик", "Курильщик"))
```


Приведем результаты анализа различий для выбранных показателей

```{r}
table <- table(dt$Social.smoker,dt$Reason.for.absence)
wilcox.test(dt$Social.smoker,dt$Reason.for.absence)
```
Т.к. значение p-value значительно меньше 0.05, то делаем вывод, что на предоставленном датасете выбранные показатели зависимы.

2. Попробуем выяснить зависимость класса (Причина отгула) от непрерывного показателя Weight (Вес) 

```{r}
table <- table(dt$Reason.for.absence)
boxplot(dt$Reason.for.absence ~ dt$Weight, dt)

wilcox.test(dt$Reason.for.absence, dt$Weight)
```

Т.к. значение p-value значительно меньше 0.05, то так же делаем вывод, что на предоставленном датасете выбранные показатели зависимы.

## Задание №4.
### Подготовим данные
Исключим показатель ID (номер работника)
```{R}
dt["ID"]<-NULL

names(dt)

indClass <- 1 #1 - причина отгула, 4 - сезон

names(dt)[indClass]
```

**Проверим наличие пропусков**

```{r}
na <- apply(dt, 2, function(v) sum(is.na(v))) # v - vector
na
```

**Пропусков нет**

**Затем разделим весь датасет на обучающую и тестовую выборку** 

```{r}
train.size <- floor(nrow(dt) * .75) # отбираем 75 процентов имеющихся объектов

train.ind <- sample(seq_len(nrow(dt)), size = train.size) 

dt.train <- dt[train.ind, ]
dt.test <- dt[-train.ind, ]

barplot(table(dt.train$Reason.for.absence))
```

### 4.1 Выполним классификацию данных.

### 1. С помощью метода knn

```{r}
library(class)
 # устраняем из таргет таблицы показатель класса, затем передаем обучающее множество с известным показателем класса и тестовое множество без показателя класса, необязательный параметр k=11 - кол. соседей  
predicted <- knn(train = dt.train[, -indClass], cl = dt.train[, indClass], test = dt.test[-indClass], k=11)

# отобразим начало вектора 
head(predicted)

```
**Посчитаем точность классификации**

```{r}
#Выполним сопоставление тестовых и натренированных данных
sum(predicted == dt.test[, indClass])/ nrow(dt.test)
```

**Построим матрицу ошибок**

```{r}
table = table(PREDICTED = predicted, REAL = dt.test[, indClass])

table

mosaicplot(table)
```

### 2. С помощью дерева решений

```{r}
library(tree)
dt.train$Reason.for.absence = as.factor(dt.train$Reason.for.absence)
tree <- tree(Reason.for.absence ~ ., dt.train)

summary(tree)

plot(tree)
text(tree, pretty = 1)
title(main = "Classification Tree")

predicted <- predict(tree, dt.test[,-indClass], type="class")
```
**Точность при использовании tree**
```{r}
sum(predicted == dt.test[, indClass])/nrow(dt.test)
```

### 3. С помощью случайного леса 

```{r}
library(randomForest)

reason.for.absence.rf = randomForest(Reason.for.absence ~ ., dt.train)
reason.for.absence.rf
```

**Оценим важность показателей**

```{r}
var.imp <- importance(reason.for.absence.rf)
var.imp

best.params <- var.imp[var.imp >35, ]
best.params
```

**При использовании алгоритма "случайный лес" получили очень большую ошибку (порядка 50%), поэтому оценки важности показателей находятся на низком уровне** 

**Точность при использовании randomForest**
```{r}
predicted <- predict(reason.for.absence.rf, dt.test[,-indClass], type="class")

sum(predicted == dt.test[, indClass])/nrow(dt.test)
```

### 4. С помощью байесовской классификации

**Сменим показатель с причины отгула на сезон(время года), потому что классификация по причине прогула в данном методе не рассчитывается.**

```{r}
library(naivebayes)

# Сменим показатель, потому что классификация по причине прогула в данном методе не рассчитывается.
indClass <- 4 #1 - причина отгула, 4 - сезон

# получим заново тренировочный датасет, чтобы привести тип показателя к значениям по умолчанию.
dt.train <- dt[train.ind, ]
dt.train$Season = as.factor(dt.train$Season)

nb <- naivebayes::naive_bayes(Season ~., dt.train) 


summary(nb)

predicted <- predict(nb, dt.test[,-indClass], type="class")

predicted

table(PREDICTED = predicted, REAL = dt.test[, indClass])
```

**Точность при использовании naive_bayes**

```{r}
sum(predicted == dt.test[, indClass])/nrow(dt.test)
```

### Задание 5. Выполним анализ важности показателей с помощью пакета randomForest.

**Пакет randomForest с порогом в 35 ед. (п.4) выявил следующие наиболее важные показатели** 

1. Month.of.absence  = 44.91296     
2. Work.load.Average.day =  46.07497  
3. Hit.target = 35.803
4. Absenteeism.time.in.hours = 71.13946

### Задание 6. Выполним классификацию данных методом randomForest на подмножестве "важных" показателей из п.5

**1. подготовим датасет** 

```{r}
# Сформируем набор выделенных признаков
selectedFeatures <- c("Reason.for.absence","Month.of.absence", "Work.load.Average.day", "Hit.target", "Absenteeism.time.in.hours")

# Выберем из тренировочного и тестового датасета выделенные признаки
dtWithSpecialFeature.train <- data.frame(dt.train[,selectedFeatures])
dtWithSpecialFeature.test <- data.frame(dt.test[,selectedFeatures]) 

# Сменим тип данных для задачи классификации 
dtWithSpecialFeature.train$Reason.for.absence = as.factor(dtWithSpecialFeature.train$Reason.for.absence)

# установим целевой индетификатор класса (1 - причина отгула )
indClass <- 1 

#классифицируем методов randomForest
reason.for.absence.rf = randomForest(Reason.for.absence ~ ., dtWithSpecialFeature.train)
```

**информация о классификации**

```{R}
reason.for.absence.rf
```

**Точность классификации с учетом "важных" показателей**

```{r}
predicted <- predict(reason.for.absence.rf, dtWithSpecialFeature.test[,-indClass], type="class")

sum(predicted == dtWithSpecialFeature.test[, indClass])/nrow(dtWithSpecialFeature.test)
```

## Вывод

В данной практической работе были изучены:

1. Основные компоненты языка R 
2. Методы обработки данных перед их исследованием
3. Методы классификации данных с помощью базовых и сторонних пакетов языка R 
4. Методы визуализации результатов обработки данных
5. Методы тестирования зависимостей показателей между собой
6. Методы оценки важности показателей