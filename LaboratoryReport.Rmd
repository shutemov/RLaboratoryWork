---
title: "LaboratoryReport"
author: "Shutemov A, 6371"
date: "13 11 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Задание №1. Загружаем датасет.
Данный датасет использовался в предыдущей практической работе и содержит данные о медицинских отгулах работников на предприятии.

```{r}
path = "C:\\Users\\HP\\Documents\\GitHub\\RLaboratoryWork\\Absenteeism_at_work.csv"

dt <- read.table(path, header = T, sep=";")
```
### Размерность датасета
```{r}
dim(dt)
```
```{r}
names(dt)
```

### Отобразим таблицу частот классов
```{r}
tbl <- table(dt$Reason.for.absence)
tbl
```

## Задание №2. Выполним статистический анализ по показателям.

Приведем 5 статистик по показателям:

1. Причина отсутствия
2. Месяц в котором было зафиксировано отсутвие
3. Сезон
4. Индекс массы тела работника
5. Время отсутвия в часах


```{r}
summary(dt[,c("Reason.for.absence","Month.of.absence","Seasons","Body.mass.index","Absenteeism.time.in.hours")])
```
Отрисуем графики зависимостей:

1. Предположим, что причина отсутвия по медицинским причинам связана с индексом массы тела работника: 

```{r, echo=FALSE}
plot(dt$Reason.for.absence, dt$Body.mass.index)
```

Но, как видно, объекты распределены довольно равномерно.

2. Возьмем другую пару, индекс массы тела и рост работника:

```{r, echo=FALSE}
plot(dt$Body.mass.index, dt$Height)
```

Здесь уже виднеется некоторая корреляция данных.

3. Также построим график зависимости причины отсутствия и месяца:

```{r, echo=FALSE}
plot(dt$Reason.for.absence, dt$Month.of.absence)
```

Распределение объектов, так же как и в первом пункте, выглядит равномемерным.

## Задание №3. Выполним статистический анализ зависимости класса от отдельных показателей.

Для этого исследуем зависимость причин отгула работника от его социального статуса "курильщик":

1. Т.к. эти показатели являются качественными, построим таблицу сопряженности


```{r}
table <- table(dt$Reason.for.absence, dt$Social.smoker)

table

#fisher.test(table,simulate.p.value=TRUE,B=2e8)
```
Отрисуем barplot этой зависимости:

```{r}
# Class ~ f1
tableClassOfF1 = table(dt$Social.smoker,dt$Reason.for.absence)
barplot(tableClassOfF1, legend.text = c("Не курильщик", "Курильщик"))
```


Приведем результаты анализа различий для выбранных показателей

```{r}
table <- table(dt$Social.smoker,dt$Reason.for.absence)
wilcox.test(dt$Social.smoker,dt$Reason.for.absence)
```
Т.к. значение p-value значительно меньше 0.05, то делаем вывод, что на предоставленном датасете выбранные показатели зависимы.

2. Попробуем выяснить зависимость класса (Причина отгула) от непрерывного показателя Weight (Вес) 

```{r}
table <- table(dt$Reason.for.absence)
boxplot(dt$Reason.for.absence ~ dt$Weight, dt)

wilcox.test(dt$Reason.for.absence, dt$Weight)
```

Т.к. значение p-value значительно меньше 0.05, то так же делаем вывод, что на предоставленном датасете выбранные показатели зависимы.

## Задание №4.
### Подготовим данные
Исключим показатель ID (номер работника)
```{R}
dt["ID"]<-NULL

names(dt)

indClass <- 1 #1 - причина отгула, 4 - сезон

names(dt)[indClass]
```

**Проверим наличие пропусков**

```{r}
na <- apply(dt, 2, function(v) sum(is.na(v))) # v - vector
na
```

Пропусков нет.

**Мы имеем разную природу показателей (сезоны - категориальный признак, время - непрерывный), поэтому нормализуем наши данные**

```{r}
library(magrittr)
min.max <- function(v)(v - min(v))/(max(v)-min(v))

dt.scaled <- apply(dt[,-indClass], 2, min.max) # нормализованная таблица
```

**Затем разделим весь датасет на обучающую и тестовую выборку** 

```{r}
train.size <- floor(nrow(dt) * .75) # отбираем 75 процентов имеющихся объектов

train.ind <- sample(seq_len(nrow(dt)), size = train.size) 

dt.train <- dt[train.ind, ]
dt.test <- dt[-train.ind, ]

barplot(table(dt.train$Reason.for.absence))
```

### 4.1 Выполним классификацию данных.

### 1. С помощью метода knn

```{r}
library(class)
 # устраняем из таргет таблицы показатель класса, затем передаем обучающее множество с известным показателем класса и тестовое множество без показателя класса, необязательный параметр k=11 - кол. соседей  
predicted <- knn(train = dt.train[, -indClass], cl = dt.train[, indClass], test = dt.test[-indClass], k=11)

# отобразим начало вектора 
head(predicted)

```
**Посчитаем точность классификации**

```{r}
#Выполним сопоставление тестовых и натренированных данных
sum(predicted == dt.test[, indClass])/ nrow(dt.test)
```

**Построим матрицу ошибок**

```{r}
table = table(PREDICTED = predicted, REAL = dt.test[, indClass])

table

mosaicplot(table)
```

### 2. С помощью дерева решений

```{r}
library(tree)
dt.train$Reason.for.absence = as.factor(dt.train$Reason.for.absence)
tree <- tree(Reason.for.absence ~ ., dt.train)

summary(tree)

plot(tree)
text(tree, pretty = 1)
title(main = "Classification Tree")

predicted <- predict(tree, dt.test[,-indClass], type="class")
```
**Точность при использовании tree**
```{r}
sum(predicted == dt.test[, indClass])/nrow(dt.test)
```


### 3. С помощью случайного леса 
```{r}
library(randomForest)

reason.for.absence.rf = randomForest(Reason.for.absence ~ ., dt.train)
reason.for.absence.rf

var.imp <- importance(reason.for.absence.rf)
var.imp

best.params <- var.imp[var.imp >50, ]
best.params

predicted <- predict(reason.for.absence.rf, dt.test[,-indClass], type="class")

```

**При использовании алгоритма "случайный лес" получили очень большую ошибку (порядка 50%), поэтому оценки важности показателей находятся на низком уровне** 

**Точность при использовании randomForest**
```{r}
sum(predicted == dt.test[, indClass])/nrow(dt.test)
```

### 4. С помощью байесовской классификации

```{r}
library(naivebayes)

# Сменим показатель, потому что классификация по причине прогула в данном методе не рассчитывается.
indClass <- 4 #1 - причина отгула, 4 - сезон

# получим заново тренировочный датасет, чтобы привести типы показатель к значениям по умолчанию.
dt.train <- dt[train.ind, ]
dt.train$Season = as.factor(dt.train$Season)

nb <- naivebayes::naive_bayes(Season ~., dt.train) 


summary(nb)

# Posterior probabilities
predicted <- predict(nb, dt.test[,-indClass], type="class")

predicted

table(PREDICTED = predicted, REAL = dt.test[, indClass])
```

**Точность при использовании naive_bayes**

```{r}
sum(predicted == dt.test[, indClass])/nrow(dt.test)
```

### 4.2  Для каждого метода получим оценки точности классификации на обучающем и тестовом множестве.
